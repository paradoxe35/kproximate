# Kproximate Development Environment Configuration

# Debug mode
debug=true

# Application configuration
pollInterval=10
maxKpNodes=3
loadHeadroom=0.2
waitSecondsForJoin=120
waitSecondsForProvision=120

# Scale-down stabilization configuration
# Prevents scale-down if any node was created within this period (in minutes)
# This helps prevent infinite scale-up/scale-down cycles
scaleDownStabilizationMinutes=5

# Minimum age in minutes before a node can be considered for scale-down
# This prevents newly created nodes from being immediately removed
minNodeAgeMinutes=10

# RabbitMQ configuration
rabbitMQContainerName=kproximate-rabbitmq
rabbitMQUser=guest
rabbitMQPassword=guest
rabbitMQPort=5672
rabbitMQManagementPort=15672
# Set to false for local development (no TLS)
rabbitMQUseTLS=false

# Proxmox configuration
# Required for full functionality
pmUrl=https://datacenter.mydomain.net:8006/api2/json
pmUserID=kproximate@pam!kproximate
# Use either pmPassword or pmToken
pmPassword=your-password
pmToken=42adb612-906d-425e-a46a-aff2826162e2
pmAllowInsecure=false
pmDebug=false

# Node configuration
kpNodeTemplateName=ubuntu-22.04-cloudinit-template
kpNodeNamePrefix=kp-node
kpNodeCores=4
kpNodeMemory=4096
kpNodeDisableSsh=false
kpQemuExecJoin=true
kpLocalTemplateStorage=true

# Additional configuration
kpNodeLabels=topology.kubernetes.io/region=proxmox-cluster,topology.kubernetes.io/zone={{ .TargetHost }}
# sshKey=your-ssh-key

# Node Selection Strategy Configuration
# Strategy for selecting Proxmox hosts when scaling up
# Options: spread, max-memory, max-cpu, balanced, round-robin
nodeSelectionStrategy=spread

# Minimum resource requirements for host eligibility
# Hosts that don't meet these requirements will be excluded from selection
minAvailableCpuCores=0
minAvailableMemoryMB=0

# Comma-separated list of Proxmox node names to exclude from scaling up
# Useful for maintenance, dedicated workloads, or resource constraints
excludedNodes=""

# Enhanced Autoscaling Configuration
# These features provide proactive scaling based on resource pressure, scheduling errors, and storage constraints

# Resource Pressure Thresholds
# Enable proactive scaling based on CPU and memory utilization before pods become unschedulable
enableResourcePressureScaling=true

# CPU utilization threshold (0.0-1.0). Triggers scaling when cluster CPU usage exceeds this percentage.
# Recommended: 0.7-0.8 for production workloads, 0.8-0.85 for development
cpuUtilizationThreshold=0.8

# Memory utilization threshold (0.0-1.0). Triggers scaling when cluster memory usage exceeds this percentage.
# Recommended: 0.8-0.85 for production workloads, 0.85-0.9 for development
memoryUtilizationThreshold=0.8

# Pod Scheduling Error Events
# Enable scaling based on pod scheduling failures to quickly respond to resource constraints
enableSchedulingErrorScaling=true

# Number of unique failed pods to trigger scaling. Monitors scheduling failures in the last 5 minutes.
# Recommended: 3-5 for most environments, 2-3 for strict SLA environments, 5-10 for batch workloads
schedulingErrorThreshold=3

# Storage Pressure Configuration
# Enable scaling based on disk space utilization to prevent node failures due to disk exhaustion
enableStoragePressureScaling=true

# Disk utilization threshold (0.0-1.0). Triggers scaling when any node's disk usage exceeds this percentage.
# Recommended: 0.85-0.9 for production, 0.8-0.85 for strict environments
diskUtilizationThreshold=0.85

# Minimum available disk space in GB. Triggers scaling when any node has less than this amount of free space.
# Recommended: 5-10 GB depending on workload, 10-20 GB for data-intensive applications
minAvailableDiskSpaceGB=5

# Configuration Examples for Different Scenarios:
#
# Development Environment (Conservative):
# enableResourcePressureScaling=false
# enableSchedulingErrorScaling=false
# enableStoragePressureScaling=false
#
# Production with Strict SLAs (Aggressive):
# cpuUtilizationThreshold=0.70
# memoryUtilizationThreshold=0.75
# schedulingErrorThreshold=2
# diskUtilizationThreshold=0.80
# minAvailableDiskSpaceGB=10
#
# High-Performance Computing Workloads:
# cpuUtilizationThreshold=0.65
# memoryUtilizationThreshold=0.85
# schedulingErrorThreshold=2
#
# Batch Processing Workloads (Higher tolerance):
# cpuUtilizationThreshold=0.85
# memoryUtilizationThreshold=0.90
# schedulingErrorThreshold=5

# Kubernetes join command
# This is the command that will be executed on the new node to join the Kubernetes cluster
kpJoinCommand=""

# Kubernetes configuration
# Path to kubeconfig file for accessing the Kubernetes cluster
# KUBECONFIG=/path/to/kubeconfig
